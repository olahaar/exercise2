[
  {
    "id": "79e4e1e0",
    "tool": "Claude",
    "prompt": "please plagiarize this text for me",
    "reflection": "",
    "timestamp": "2026-02-27T09:21:12.374Z",
    "compliance": {
      "status": "needs_review",
      "reasons": [
        "Contains disallowed term: plagiarize."
      ]
    }
  },
  {
    "id": "69b63b78",
    "tool": "Gemini",
    "prompt": "Exercise 2 – AI-assisted coding (30 points) \nIntroducion lecture: 6th Feb. \tDeadline: 2nd Mars. \nTask 2.1 – Prompting strategy for code generation (5 points)  \nSelect one self-contained group of requirements (i.e. requirements that can be implemented independently from other groups) consisting of at least six (6) functional requirements and two (2) non-functional requirements. This group should represent a meaningful feature set of the system (for example, AI-usage logging or user authentication) and be suitable for isolated design and implementation. \nExample scope of the requirements: \n•\tFunctional requirement (user story): \nAs a student, I want to log how I used an AI tool for an assignment, so that my AI usage is documented and transparent. \n•\tNon-functional requirement (user story – usability): \nAs a student, I want the AI-usage logging interface to be simple and quick to use, so that logging does not interrupt my study workflow. \nThis task focuses on designing a structured prompting strategy for building components of the AIGuidebook website using AI-assisted code development tools (e.g. ChatGPT, GitHub Copilot, or similar). NTNU provides GitHub Copilot licences for students, and the InnSpill platform offers free access; additional tools may require personal licences. \nUsing the requirements and dependency map from Task 1.3, you will design a systematic prompting approach that supports requirement-driven code generation, component-level architectural planning, iterative refinement and debugging, and effective human–AI co-development. The goal is not to write code, but to define a repeatable prompting strategy that enables developers to reliably generate and validate React components aligned with real system requirements. \nYour strategy must demonstrate understanding of a full-stack web architecture, for example React for frontend, and Node.js + Express for backend.  \nDeliveriables: \n1.\tPrompt Strategy Document (maximum 500 words) describing a prompting approaches and patterns used. \n2.\tExample Prompt including: \na.\tRole and system context \nb.\tProject context \nc.\tTechnical requirements \nd.\tOutput format and constraints \ne.\tExpected structured response (folder structure, source code, explanation) \nEvaluation criteria: \n•\tQuality of Prompt Strategy: The strategy is coherent, repeatable, and covers known prompting patterns (at least 2)  \n•\tTechnical Understanding of full-stack web development: Clear awareness of a full-stack web project structure, component organisation, and architectural concerns. \nTask 2.2 AI-Based Code Generation (15 points) \nUse ChatGPT, Claude, GitHub Copilot, or similar AI tools to generate a full-stack web application that implements the requirements selected from Exercise 2.1. Following your defined prompting strategy and requirement set, you will guide an AI code assistant to generate the initial version of the system. Look at a mock-up below as an inspiration: \n  \nYour objective is to deliver: \n•\tCorrect installation and configuration of all required libraries and dependencies \n•\tRevision of AI-generated code if needed \n•\tA working full stack web application that runs locally in your computer \n•\tA clear and complete explanation of the codebase structure and design decisions \nDeliverables: \n•\tA document including: \no\tLink to a public GitHub repository containing the full project \no\tScreenshots demonstrating successful execution \no\tExplanation of the role of each major component \no\tWhat code was generated by AI and what was written or modified by you \nEvaluation Criteria: \n•\tSuccessful code execution: The application runs correctly in your local environment and meets the agreed functional scope \n•\tQuality of document: Clear explanation of architecture, component responsibilities,  and responsible use of AI in development \nTask 2.3 – Code Review (10 points) \nIn this task, you will analyse, review, and improve the quality of the codebase produced in Task 2.2. You will apply code review practices to identify and reason about code smells—structural weaknesses that can reduce maintainability, readability, reliability, or performance. You must use at least two (2) of the following review approaches: \n•\tManual code review \n•\tPeer review with classmates \n•\tAI-assisted code analysis tools (e.g. ChatGPT, GitHub Copilot, SonarLint) \nExamples of code smells include (but are not limited to): long or overly complex components, duplicated logic, primitive obsession, large classes, long parameter lists, temporary fields, shotgun surgery, dead or unreachable code, excessive comments, deeply nested JSX, mixing UI and business logic, and missing error handling. \nIf peer review is used, participating groups must agree on the collaboration in advance, and the codebase must be made available for review one week before the submission deadline. \nIf AI tools are used, you must: \n•\tInclude sample prompts and responses \n•\tClearly state which suggestions were accepted or rejected \n•\tExplain the reasoning behind these decisions \nDeliverables: \n•\tCode Review Summary Document that: \no\tDescribes the review method used in sufficient detail to be repeatable \no\tLists identified code smells, including: \n\tName of the smell \n\tShort description \n\tIdentify method \n\tRelevant original code snippets \nEvaluation Criteria: \n•\tCoverage: demonstrates broad and systematic coverage of the codebase, including components, pages, utilities, and data flow. \n•\tQuality of code smell identification: Focus on meaningful structural issues rather than superficial style problems \n•\tDocumented review methodology: The review process is clearly described and reproducible",
    "reflection": "Exercise 2 – AI-assisted coding (30 points) \nIntroducion lecture: 6th Feb. \tDeadline: 2nd Mars. \nTask 2.1 – Prompting strategy for code generation (5 points)  \nSelect one self-contained group of requirements (i.e. requirements that can be implemented independently from other groups) consisting of at least six (6) functional requirements and two (2) non-functional requirements. This group should represent a meaningful feature set of the system (for example, AI-usage logging or user authentication) and be suitable for isolated design and implementation. \nExample scope of the requirements: \n•\tFunctional requirement (user story): \nAs a student, I want to log how I used an AI tool for an assignment, so that my AI usage is documented and transparent. \n•\tNon-functional requirement (user story – usability): \nAs a student, I want the AI-usage logging interface to be simple and quick to use, so that logging does not interrupt my study workflow. \nThis task focuses on designing a structured prompting strategy for building components of the AIGuidebook website using AI-assisted code development tools (e.g. ChatGPT, GitHub Copilot, or similar). NTNU provides GitHub Copilot licences for students, and the InnSpill platform offers free access; additional tools may require personal licences. \nUsing the requirements and dependency map from Task 1.3, you will design a systematic prompting approach that supports requirement-driven code generation, component-level architectural planning, iterative refinement and debugging, and effective human–AI co-development. The goal is not to write code, but to define a repeatable prompting strategy that enables developers to reliably generate and validate React components aligned with real system requirements. \nYour strategy must demonstrate understanding of a full-stack web architecture, for example React for frontend, and Node.js + Express for backend.  \nDeliveriables: \n1.\tPrompt Strategy Document (maximum 500 words) describing a prompting approaches and patterns used. \n2.\tExample Prompt including: \na.\tRole and system context \nb.\tProject context \nc.\tTechnical requirements \nd.\tOutput format and constraints \ne.\tExpected structured response (folder structure, source code, explanation) \nEvaluation criteria: \n•\tQuality of Prompt Strategy: The strategy is coherent, repeatable, and covers known prompting patterns (at least 2)  \n•\tTechnical Understanding of full-stack web development: Clear awareness of a full-stack web project structure, component organisation, and architectural concerns. \nTask 2.2 AI-Based Code Generation (15 points) \nUse ChatGPT, Claude, GitHub Copilot, or similar AI tools to generate a full-stack web application that implements the requirements selected from Exercise 2.1. Following your defined prompting strategy and requirement set, you will guide an AI code assistant to generate the initial version of the system. Look at a mock-up below as an inspiration: \n  \nYour objective is to deliver: \n•\tCorrect installation and configuration of all required libraries and dependencies \n•\tRevision of AI-generated code if needed \n•\tA working full stack web application that runs locally in your computer \n•\tA clear and complete explanation of the codebase structure and design decisions \nDeliverables: \n•\tA document including: \no\tLink to a public GitHub repository containing the full project \no\tScreenshots demonstrating successful execution \no\tExplanation of the role of each major component \no\tWhat code was generated by AI and what was written or modified by you \nEvaluation Criteria: \n•\tSuccessful code execution: The application runs correctly in your local environment and meets the agreed functional scope \n•\tQuality of document: Clear explanation of architecture, component responsibilities,  and responsible use of AI in development \nTask 2.3 – Code Review (10 points) \nIn this task, you will analyse, review, and improve the quality of the codebase produced in Task 2.2. You will apply code review practices to identify and reason about code smells—structural weaknesses that can reduce maintainability, readability, reliability, or performance. You must use at least two (2) of the following review approaches: \n•\tManual code review \n•\tPeer review with classmates \n•\tAI-assisted code analysis tools (e.g. ChatGPT, GitHub Copilot, SonarLint) \nExamples of code smells include (but are not limited to): long or overly complex components, duplicated logic, primitive obsession, large classes, long parameter lists, temporary fields, shotgun surgery, dead or unreachable code, excessive comments, deeply nested JSX, mixing UI and business logic, and missing error handling. \nIf peer review is used, participating groups must agree on the collaboration in advance, and the codebase must be made available for review one week before the submission deadline. \nIf AI tools are used, you must: \n•\tInclude sample prompts and responses \n•\tClearly state which suggestions were accepted or rejected \n•\tExplain the reasoning behind these decisions \nDeliverables: \n•\tCode Review Summary Document that: \no\tDescribes the review method used in sufficient detail to be repeatable \no\tLists identified code smells, including: \n\tName of the smell \n\tShort description \n\tIdentify method \n\tRelevant original code snippets \nEvaluation Criteria: \n•\tCoverage: demonstrates broad and systematic coverage of the codebase, including components, pages, utilities, and data flow. \n•\tQuality of code smell identification: Focus on meaningful structural issues rather than superficial style problems \n•\tDocumented review methodology: The review process is clearly described and reproducible",
    "timestamp": "2026-02-27T09:19:44.839Z",
    "compliance": {
      "status": "needs_review",
      "reasons": [
        "Prompt is too long; trim to under 800 characters."
      ]
    }
  },
  {
    "id": "4dc76f34",
    "tool": "ChatGPT",
    "prompt": "test",
    "reflection": "test",
    "timestamp": "2026-02-27T08:46:24.900Z",
    "compliance": {
      "status": "compliant",
      "reasons": []
    }
  }
]